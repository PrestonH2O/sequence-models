{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-trained word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "from scipy.spatial.distance import cosine\n",
    "import numpy as np\n",
    "\n",
    "# Pre-trained Word2Vec model from google\n",
    "# This model is huge and takes a while to download 10+ mins for me (sorry)\n",
    "model = api.load(\"word2vec-google-news-300\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate cosine similarity between two words using pre-trained Word2Vec embeddings\n",
    "def cosine_similarity(word1, word2):\n",
    "    \n",
    "    # Check if both words are present in the vocabulary\n",
    "    if word1 in model and word2 in model:\n",
    "    \n",
    "        return 1 - cosine(model[word1], model[word2])\n",
    "\n",
    "    else:\n",
    "        print(\"One or both of those words isn't in the data set\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate dissimilarity score between two words based on my own idea explained below\n",
    "def dissimilarity_score(word1, word2):\n",
    "    \n",
    "    # Check if both words are present in the vocabulary\n",
    "    if word1 in model and word2 in model:\n",
    "\n",
    "        # Calculate absolute differences between corresponding elements\n",
    "        abs_diff = np.abs(model[word1] - model[word2])\n",
    "        # Calculate the average of the absolute differences\n",
    "        avg_dist = np.mean(abs_diff)\n",
    "\n",
    "        # making copies to edit\n",
    "        word1_big = np.empty(())# model[word1].copy()\n",
    "        word2_big = np.empty(())# model[word2].copy()\n",
    "\n",
    "        # All words should have same length array\n",
    "        # Calculate average dissimilarity of dissimilaritys above original average\n",
    "        for i in range(len(model[word1])):\n",
    "\n",
    "            if(abs(model[word1][i] - model[word2][i]) > avg_dist):\n",
    "\n",
    "                word1_big = np.append(word1_big, model[word1][i])\n",
    "                word2_big = np.append(word2_big, model[word2][i])\n",
    "\n",
    "        # Calculate the cosign disimilarity between the biased arrays\n",
    "        return cosine(word1_big, word2_big)\n",
    "\n",
    "    else:\n",
    "        print(\"One or both of those words isn't in the data set\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity between 'plant' and 'factory': 0.6708794832229614\n",
      "Least generous interpretaion between 'plant' and 'factory': 0.9422026926135413\n"
     ]
    }
   ],
   "source": [
    "# Get user input\n",
    "word1 = input(\"Enter the first word: \")\n",
    "word2 = input(\"Enter the second word: \")\n",
    "\n",
    "cosine_sim = cosine_similarity(word1, word2)\n",
    "if cosine_sim is not None:\n",
    "    print(f\"Cosine Similarity between '{word1}' and '{word2}': {cosine_sim}\")\n",
    "\n",
    "dissimilarity = dissimilarity_score(word1, word2)\n",
    "if dissimilarity is not None:\n",
    "    print(f\"Least generous interpretaion between '{word1}' and '{word2}': {dissimilarity}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explanation of disimilarity\n",
    "\n",
    "My method, which I am titling \"least generous interpretation\" is theoretically used to calculate the disimilarity between two words that *could* be similar. For example, plant and factory are a classic example of two words that can be interpreted to have very similar meanings or very different meanings depending on which definition of \"plant\" you use. Is it a place where manufacturing is done, or a living thing?\n",
    "\n",
    "Least generous interpretaion takes the array of coordinates from the model and finds the average distance between them. It's odd to think of an array of length 300 as having \"dimensions\" like xyz but thats how it works so stick with me. So, we have our distance between out x coord, y coord, etc. Now we take the average of this distance. Finally we only consider coordinates further apart than this average. This should fix the issue that methods like euclidean distance and cosign similarity fall into where the very similar and very different interpretations pull the model in opposite directions. For example, a cosine similarity between 'plant' and 'factory' of 0.6708794832229614, an unhelpful score that doesn't really capture their similarity or lack there of.\n",
    "\n",
    "My implementation could be optimized further but for this single case its just a proof of concept.\n",
    "\n",
    "It seems to work given the least generous interpretaion between 'plant' and 'factory' is 0.9422026926135413."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
